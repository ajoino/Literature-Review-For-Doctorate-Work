\begin{review}{Gentner1983Structure}
        {N/A}
        {
            A theory of analogy must describe how the meaning of an analogy is derived from the meanings of its parts. 
            In the structure-mapping theory, the interpretation rules are characterized as implicit rules for mapping knowledge about a base domain into a target domain. 
            Two important features of the theory are (a) the rules depend only on syntactic properties of the knowledge representation, and not on the specific content of the domains; and (b) the theoretical framework allows analogies to be distinguished cleanly from literal similarity statements, applications of abstractions, and other kinds of comparisons. 
            Two mapping principles are described: (a) Relations between objects, rather than attributes of objects, are mapped from base to target; and (b) The particular relations mapped are determined by systematicity, as defined by the existence of higher-order relations. Â© 1983.
        }
    The objective in this paper is to create a framework for finding analogies.
    According to the author, the three fundamental kinds of comparisons are \emph{literal similarity}, \emph{analogy} and \emph{abstraction}.
    
    A literal similarity between two objects means that they share both attributes and relations with each other.
    An example of this is "The X12 star system in the Andromeda galaxy is like our solar system.
    This means that they both share attributes (star, planets, star is yellow) and relations (planets rotates around the star, planets are colder than the star).
    
    An analogy have few attributal similarities but many relational, like a solar system and an atom (proton heavier than electrons :: sun heavier than planets etc.).
    
    Abstractions are defined in a fairly vague way, according to the author "Abstraction differs from analogy and the other comparisons in having few object-attributes in the base domain as well as few object-attributes in the target domain."
    
    The 'structure'-part of the name of the paper comes from how the author orders different predicates.
    A second order predicate has at least one first order predicate as its arguments, e.g. CAUSE {AND [PUNCTURE(vessel), CONTAIN(vessel, water)], FLOW-FROM(water, vessel)}.
    This means that the cause of water flowing out of the vessel is that the vessel was punctured.
    The first order predicates are PUNCTURE, CONTAIN, FLOW-FROM because they have 'regular' objects as their arguments, whereas AND have first order predicates as its arguments.
    This makes AND a second order predicate.
    Similarly,  because CAUSE have a second order predicate as one of its arguments it is a third order predicate.
    
    To know which relation is more important, the author suggests to look at the order of the relation structure.
    A relation is thought of as more important if it has a deeper structure, which often results in more shallow (attributional) properties being disgarded.
    
    This paper is very abstract and, as the title suggests is more of a framework.
    It doesn't present any ways to implement it, though that was never the intention it would seem.
    Overall it provides an interesting way of thinking of all of this but I'm not sure how useful it actually is.
    But the paper is cited in a lot of articles so I'm sure there is a lot of things I just haven't started thinking about yet.
\end{review}
